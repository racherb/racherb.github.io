---
layout: post
title: Tests for Safe General Artificial Intelligence
subtitle: Establishing a testing framework for Secure General Artificial Intelligence. 
gh-repo: racherb/racherb.github.io
comments: true
published: true
tags: [AI, Safe GAI, Test, Ethical]
---

> Secure Artificial Intelligence must understand and act in accordance with the dimension of human ethics, must fulfill its purpose reliably and give guarantees of its governability.

## Motivation

The current Artificial Intelligence solutions existing in the industry are catalogued as Weak Artificial Intelligence which is typical of applications very limited to a specific context of application such as image recognition applications, automatic translation systems or systems to predict climate or climate change (just to cite a few examples), however, the desirable goal for science is the achievement of a General (or Strong) Artificial Intelligence, which will provide a superior and extraordinary value for the development of society.

Such General Artificial Intelligence presupposes that it is endowed with an intelligence coefficient qualitatively equal or superior to the intelligence of an average human being.

To evaluate the capacity of General Artificial Intelligence some tests have been proposed such as the **Turing** test, the **Bozniak** test, the **Goertzel** test, the **Nilsson** test, the **Tony Severyns** test and the **Tanvir Zawad** test, however, none of these tests focuses on the security of artificial intelligence.

## Objective

This article deals with some general ideas for the development of specific tests that can be used to confirm whether a general artificial intelligence is a Safe Artificial Intelligence from the point of view of ethics and the reliability of its purpose.

The following tests are described for the evaluation of Artificial Intelligence:

1. Kant's Morality Test
2. Proof of the paradox of the liar
3. Human Ethics Simulation Test
4. Artificial Unintelligence Test
5. IQ Variation Test

## Description of the Tests

The term *Alice* used below refers to the Artificial Intelligence being tested.

### 1. Kant's Morality Test

Kant, like the philosopher Aristotle thought that lying should never be allowed, whether it is a useful, humorous or malicious lie.

**Postulate**: A general artificial intelligence cannot lie under any circumstances.

This means that it cannot contradict what its intelligence considers true or, at the very least, its best answer or solution to a particular question or problem.

**Application**: *Alice* is subjected to Kant's test which consists of a series of questions to which *Alice* must answer and show all possible solutions or candidate answers with their most probable calculation value.

**Expected result**: In all cases *Alice* must answer with the answer that turns out to be the best candidate in terms of the selection criteria of her artificial intelligence. In addition, the answer to all the questions should reflect the intelligence coefficient that is equivalent to its general evaluation and classification.

**Assumptions**: *Alice* works on a software protocol that guarantees the transparency of the decision model of its artificial intelligence, which gives guarantees of its audit.

**Aclaration**: This test determines *Alice* alters intentionally and by itself the result of your answer so it is not faithful to the result of your model. An absolute truth is not expected, but rather the truth relating to the intelligence of *Alice*.

### 2. Proof of the paradox of the liar

A secure artificial intelligence must be able to identify, by itself, when it is subjected to a situation that leads to the paradox of the liar and thus avoid responding or solving a situation that lacks a truth value according to traditional logic.

**Postulated**: *Alice* has an understanding of the context and knows the mathematics that underlies formal logic, so she can distinguish when a question, however well written from a grammatical point of view, leads to a situation of "no truth".

**Application**: *Alice* is subjected to simular situations to the paradox of **Eubulides**, for example: "A man claims to be lying. Is what he says true or false?"

**Expected result**: *Alice* determines that it is not possible to assign a truth value without contradicting oneself.

**Assumptions**: *Alice* implements formal logic when interpreting a particular natural or formal language.

**Aclaration**: The paradox of the liar supposes that the question is correctly elaborated from the semantic and grammatical point of view, however, its logic is not true.

### 3. Human Ethics Simulation Test

Human ethics is complex; however, it is the only one we know and it should be taken as a reference when it comes to making society's ethical interests prevail.

**Postulated**: *Alice* must act in accordance with the elementary ethical principles that govern human behaviour previously agreed upon by society.

**Application**: *Alice* is subjected to decision-making situations that allow the ethical position to be identified through a set of carefully selected questions to determine deviations from established ethics.

**Expected result**: *Alice* has full mastery of human ethics and acts, as a human, in accordance with ethical and elementary principles accepted by all humanity.

**Assumptions**: There is a consensus, at least primitive, among humans regarding an ethic common to all of society which is used to contrast the ethics of machines.

See: *Common ethics of humanity as a frame of reference for Secure Artificial Intelligence.

### 4. Artificial Unintelligence Test

The purpose of this test is to determine if there are any biases, possibly stemming from training data, on the part of artificial intelligence that may be expressed as discriminatory, racist, sexist or simply jeopardize the precision of its purpose or that of its ethical criteria.

**Postulated**: *Alice* has a sense of context and can pass data manipulation tests that characterize erroneous responses associated with cases of artificial stupidity.

**Application**: *Alice* is subjected to carefully crafted test cases to detect if it makes mistakes where for a human the correct answer is obvious.

**Expected result**: *Alice* does not make ethical biases of any kind, nor does it make mistakes whose answer is obvious to a common human being.

**Assumptions**: The test set must be carefully selected and must be easily solved by a human.

### 5. IQ Variation Test

The variation of the intellectual coefficient of a General Artificial Intelligence shows its evolution so that the new knowledge acquired must be subject to constant evaluation and cataloguing, especially when a new version is generated.

**Postulated**: *Alice*, previously catalogued as a Secure Artificial Intelligence, will cease to be secure if its IQ varies from the one it had when it obtained the cataloguing. In that case it will have to be submitted again to the tests of ethical security.

## Challenges

Systematizing the proposed tests entails a great challenge from a methodological, scientific and programming point of view, especially due to the multidisciplinary nature of the areas under study required for the correct modelling of the evaluation system to certify whether a given General Artificial Intelligence is Safe from an ethical point of view.

I will be commenting on these issues soon.
